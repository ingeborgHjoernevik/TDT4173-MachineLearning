{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kNN new.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7fxmTqe38vz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "32ccedf1-4b64-4fea-f684-2fba0e68afd8"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import gspread\n",
        "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ec17953a78d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgspread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moauth2client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporary\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mclear_output\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_noop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m       \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mcolab_tpu_addr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'COLAB_TPU_ADDR'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# https://github.com/jupyter/notebook/issues/3159\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hun9qaBe23vJ"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import time \n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def load_data():\n",
        "  path1 = '/content/drive/My Drive/TDT4173 Maskinlæring /data_batch_1'\n",
        "  path2 = '/content/drive/My Drive/TDT4173 Maskinlæring /data_batch_2'\n",
        "  path3 = '/content/drive/My Drive/TDT4173 Maskinlæring /data_batch_3'\n",
        "  path4 = '/content/drive/My Drive/TDT4173 Maskinlæring /data_batch_4'  \n",
        "  path5 = '/content/drive/My Drive/TDT4173 Maskinlæring /data_batch_5'\n",
        "  path6 = '/content/drive/My Drive/TDT4173 Maskinlæring /test_batch'\n",
        "\n",
        "  listOfTestFiles = [path1, path2, path3, path4, path5, path6]\n",
        "\n",
        "  train = []\n",
        "  train_labels = []\n",
        "  test = []\n",
        "  test_labels = []\n",
        "\n",
        "  #For collecting Training data:\n",
        "  for file in listOfTestFiles[0:5]:\n",
        "      with open(file,'rb') as fo:\n",
        "          dict = pickle.load(fo,encoding='bytes')\n",
        "          train.append(dict[b'data'])\n",
        "          train_labels.append(dict[b'labels'])\n",
        "\n",
        "  #for collecting Testing data\n",
        "  with open(path6,'rb') as fo:\n",
        "          dict = pickle.load(fo,encoding='bytes')\n",
        "          test.append(dict[b'data'])\n",
        "          test_labels.append(dict[b'labels']) \n",
        "\n",
        "  dictData = {}\n",
        "  dictData['train_data'] = np.reshape(np.array(train),newshape=(np.array(train).shape[0]*np.array(train).shape[1],np.array(train).shape[2]))\n",
        "  dictData['train_labels'] = np.reshape(np.array(train_labels),newshape=(np.array(train_labels).shape[0]*np.array(train_labels).shape[1]))\n",
        "  dictData['test_data'] = np.reshape(np.array(test),newshape=(np.array(test).shape[0]*np.array(test).shape[1],np.array(test).shape[2]))\n",
        "  dictData['test_labels'] = np.reshape(np.array(test_labels),newshape=(np.array(test_labels).shape[0]*np.array(test_labels).shape[1]))\n",
        "  return dictData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcIdR5-DCGKK"
      },
      "source": [
        "#Run pca to find number of components d that have >p variance\n",
        "def find_components(p, train_x):\n",
        "  starttime = time.time()\n",
        "  pca = PCA()\n",
        "  pca.fit(train_x)\n",
        "  cum_sum = np.cumsum(pca.explained_variance_ratio_, axis = 0)\n",
        "  out = np.cumsum(pca.explained_variance_ratio_)\n",
        "  top_percentile = np.where(cum_sum>p)[0][0]\n",
        "  print(\"Top \",p*100, \"% is gained by choosing: \", top_percentile, \"components. Time used: \", time.time()-starttime)\n",
        "  return top_percentile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbWojTeciU_A"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(col[:1024])\n",
        "plt.plot(gray)\n",
        "plt.legend(['Colour', 'Gray'], loc='center right')\n",
        "plt.ylabel('Accumulated explained variance ratio')\n",
        "plt.xlabel(\"Number of features\")\n",
        "plt.title(\"Accumulated EVR plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sGwHcCz1dX4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "9e788c87-5103-4026-a7ef-bc3e0014a63d"
      },
      "source": [
        "#View image\n",
        "def view(image):\n",
        "  temp = image\n",
        "  if (image.shape[0]==3072): #For RGB images\n",
        "    R = temp[0:1024].reshape(32,32)\n",
        "    G = np.reshape(temp[1024:2048],newshape=(32,32))\n",
        "    B = np.reshape(temp[2048:],newshape=(32,32))\n",
        "    temp = np.dstack((R,G,B))   #for stacking all these 32,32 matrices.\n",
        "    plt.imshow(temp)\n",
        "  else: #For grayscale images\n",
        "    temp = temp.reshape(32,32)\n",
        "    plt.imshow(temp, cmap='gray')\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-6577916f76e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_train_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpncHegqsvBy"
      },
      "source": [
        "  label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "  conf = plot_confusion_matrix(make_knn(10, train_x, train_y), train_x, train_y, normalize='true',values_format  = '.2g', display_labels = label_names)\n",
        "  conf.plot(ax=ax)\n",
        "  conf.ax_.set_title(\"Validation Set Performance - Full Colour \")\n",
        "  print(\"Time used on plot cnf: \", time.time()-starttime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJZYzjhAwMQT"
      },
      "source": [
        "#Transform RGB to gray values. Code from https://github.com/ppplinday/Picture-Classification-PCA-KNN/blob/master/KNN-PCA.py\n",
        "def RGB_to_gray(data):\n",
        "  data = data.reshape(data.shape[0],3,32,32).transpose(0,2,3,1).astype(\"float\")\n",
        "  newdata = np.zeros([data.shape[0], data.shape[1], data.shape[2]], float)\n",
        "  num    = data.shape[0]\n",
        "  height = data.shape[1]\n",
        "  width  = data.shape[2]\n",
        "  for n in range(num):\n",
        "      for row in range(height):\n",
        "          for col in range(width):\n",
        "              newdata[n, row, col] = 0.299 * data[n, row, col, 0] + 0.587 * data[n, row, col, 1] + 0.114 * data[n, row, col, 2]\n",
        "  newdata = newdata.reshape(data.shape[0], 32*32)\n",
        "  return newdata\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfsd9eEqHIL_"
      },
      "source": [
        "#Transform into d components\n",
        "def transform_to(d, X):\n",
        "  starttime = time.time()\n",
        "  p_pca = PCA(d)\n",
        "  out = p_pca.fit_transform(X)\n",
        "  print(\"Time used on making pca: \", time.time()-starttime)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqTepVs3E-4Z"
      },
      "source": [
        "#Making the knn with k neighbours\n",
        "def make_knn(k, X, Y):\n",
        "  starttime = time.time()\n",
        "  knn = KNeighborsClassifier(n_neighbors=k)\n",
        "  knn = knn.fit(X, Y)\n",
        "  print(\"Time used on making knn: \", time.time()-starttime)\n",
        "  return knn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juNpQDr7Qdyd"
      },
      "source": [
        "#Calculating the accuracy of the knn model on a training set X with labels Y\n",
        "def calc_accuracy(knn, X, Y):\n",
        "  starttime = time.time()\n",
        "  accuracy = knn.score(X,Y)\n",
        "  #print(\"Accuracy on validation set with k = \", knn.n_neighbors , \": \", accuracy)\n",
        "  print(\"Time used on calculating accuracy: \", time.time()-starttime)\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGttxdKeInJp"
      },
      "source": [
        "#Makes a new sheet in the \"accuracy\"-workbook, with a name based on number of features and the length of the validation set.\n",
        "def newSheet(d, val_x):\n",
        "  wb = gc.open_by_url('https://docs.google.com/spreadsheets/d/1iqm61ROBjpCUysro7AoT0yrUd6z57VmVcPQ2FlyiHXA/edit#gid=0')\n",
        "  title = \"N:\"+str(d)+\".L:\"+str(val_x.shape[0])\n",
        "  rows = 100\n",
        "  col = 2\n",
        "  makeNew = True\n",
        "  for ws in wb.worksheets():\n",
        "    if (str(ws).split()[1]==str(\"'\"+title+\"'\")):\n",
        "      sheet = ws\n",
        "      data = ws.get_all_values()\n",
        "      makeNew = False\n",
        "  if makeNew:\n",
        "    sheet = wb.add_worksheet(title, rows, col)\n",
        "    data = {'K':[0]*rows, 'Accuracy (%)':[0]*rows}\n",
        " \n",
        "  df = pd.DataFrame(data)\n",
        "  df.columns = df.iloc[0]\n",
        "  df = df.iloc[1:]\n",
        "  set_with_dataframe(sheet, df)\n",
        "  return sheet, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsF_lFo8x482"
      },
      "source": [
        "#Calculating which k that gives the best accuracy on a data set val_x, when it is trained on train_x. These values are saved in a spreadsheet called \"Accuracy\".\n",
        "def calculate_best_k(d, train_x, train_y, val_x, val_y):\n",
        "  best_k = 1\n",
        "  best_acc = 0.1\n",
        "  \n",
        "  sheet, df = newSheet(d, val_x)\n",
        "\n",
        "  for k in range(1, 60):\n",
        "    knn = make_knn(k, train_x, train_y)\n",
        "    acc = calc_accuracy(knn, val_x, val_y)\n",
        "\n",
        "    df.iloc[k-1][0]=k\n",
        "    df.iloc[k-1][1]=acc*100\n",
        "    print(\"k = \", k, \" gir acc = \", acc,\"\\n\")\n",
        "    set_with_dataframe(sheet, df)\n",
        "\n",
        "    if (acc>best_acc):\n",
        "      best_k = k\n",
        "      best_acc = acc\n",
        "  return best_k, best_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEpRNb72mXEi"
      },
      "source": [
        "def pred(knn, X):\n",
        "  starttime=time.time()\n",
        "  out = knn.predict(X)\n",
        "  print(\"Time used on predicting dataset: \", time.time()-starttime)\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hVuP24Dlyk_"
      },
      "source": [
        "#Viewing the reconstruction of the pca\n",
        "def reconstruct_test():\n",
        "  d = 165\n",
        "  pca_i = PCA(d)\n",
        "  pca_i.fit(x_train)\n",
        "  x_train_pca = pca_i.transform(x_train)\n",
        "  X_reconstructed_pca = pca_i.inverse_transform(x_train_pca)\n",
        "  print(X_reconstructed_pca.shape)\n",
        "  view(X_reconstructed_pca[100])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XFcqQt8gFam"
      },
      "source": [
        "def main_val_colour():\n",
        "  #Load dataset\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset loaded...\")\n",
        "\n",
        "  #Split dataset to training, validating and testing data.\n",
        "  x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "  train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "  val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "  mini_val_x, mini_val_y = val_x[500:], val_y[500:]\n",
        "  print(\"Dataset splitted...\")\n",
        "\n",
        "  #Calculate best k by making kNNs an checking accuracy\n",
        "  model = make_knn(1, train_x, train_y)\n",
        "  #red_y = pred(model, val_x)\n",
        "  #acc = accuracy_score(val_y, pred_y)\n",
        "  #print(\"Model gives an accuracy of: \", acc)\n",
        "\n",
        "  fig = plt.figure(figsize=[20, 20])\n",
        "  ax = fig.add_subplot(2,1,1)\n",
        "\n",
        "  starttime=time.time()\n",
        "  label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "  conf = plot_confusion_matrix(model, val_x, val_y, normalize='true',values_format  = '.2g', display_labels = label_names)\n",
        "  conf.plot(ax=ax)\n",
        "  conf.ax_.set_title(\"Validation Set Performance - Full Colour \")\n",
        "  print(\"Time used on plot cnf: \", time.time()-starttime)\n",
        "\n",
        "main_val_colour()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ohXT-RISN2"
      },
      "source": [
        "def main_val_gray():\n",
        "  #Load dataset\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset loaded...\")\n",
        "\n",
        "  #Split dataset to training, validating and testing data.\n",
        "  x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "  train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "  val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "  mini_val_x, mini_val_y = val_x[500:], val_y[500:]\n",
        "  print(\"Dataset splitted...\")\n",
        "\n",
        "  #Convert color images to gray images\n",
        "  gray_train_x = RGB_to_gray(train_x)\n",
        "  gray_val_x = RGB_to_gray(val_x) \n",
        "  print(\"Images converted...\")\n",
        "  \n",
        "  #Calculate best k by making kNNs an checking accuracy\n",
        "  model = make_knn(1, gray_train_x, train_y)\n",
        "  #pred_y = pred(model, gray_val_x)\n",
        "  #acc = accuracy_score(val_y, pred_y)\n",
        "  #print(\"Model gives an accuracy of: \", acc)\n",
        "\n",
        "\n",
        "  fig = plt.figure(figsize=[20, 20])\n",
        "  ax = fig.add_subplot(2,1,1)\n",
        "\n",
        "  starttime=time.time()\n",
        "  label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "  conf = plot_confusion_matrix(model, gray_val_x, val_y, normalize='true',values_format  = '.2g', display_labels = label_names)\n",
        "  conf.plot(ax=ax)\n",
        "  conf.ax_.set_title(\"Validation Set Performance - Full Gray \")\n",
        "  print(\"Time used on plot cnf: \", time.time()-starttime)\n",
        "\n",
        "\n",
        "main_val_gray()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDIj18jM8NJN"
      },
      "source": [
        "  fig = plt.figure(figsize=[20, 20])\n",
        "  ax = fig.add_subplot(2,1,1) \n",
        "  model = make_knn(1,train_x, train_y)\n",
        "\n",
        "  starttime=time.time()\n",
        "  label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "  conf = plot_confusion_matrix(model, train_x, train_y, normalize='true',values_format  = '.2g', display_labels = label_names)\n",
        "  conf.plot(ax=ax)\n",
        "  conf.ax_.set_title(\"Training Set Performance - Full Colour \")\n",
        "  print(\"Time used on plot cnf: \", time.time()-starttime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd8wT1Cmfln-"
      },
      "source": [
        "def main_val_colour_pca():\n",
        "  #Load dataset\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset loaded...\")\n",
        "\n",
        "  #Split dataset to training, validating and testing data.\n",
        "  x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "  train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "  val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "  mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "  print(\"Dataset splitted...\")\n",
        "\n",
        "  \n",
        "\n",
        "  #Find right number of components, according to a variance p\n",
        "  p = 0.95\n",
        "  #d = find_components(p, train_x)\n",
        "  d = 215\n",
        "\n",
        "  #Make PCA\n",
        "  pca_train_x = transform_to(d, train_x)\n",
        "  pca_val_x = transform_to(d, val_x) \n",
        "\n",
        "  \n",
        "  #Calculate best k by making kNNs an checking accuracy\n",
        "  model = make_knn(1, pca_train_x, train_y)\n",
        "  pred_y = pred(model, pca_val_x)\n",
        "  acc = accuracy_score(val_y, pred_y)\n",
        "  print(\"Model gives an accuracy of: \", acc)\n",
        "\n",
        "main_val_colour_pca()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cDjnypXaB4X"
      },
      "source": [
        "#Load dataset\n",
        "dataset = load_data()\n",
        "print(\"Dataset loaded...\")\n",
        "\n",
        "#Split dataset to training, validating and testing data.\n",
        "x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "print(\"Dataset splitted...\")\n",
        "  \n",
        "\n",
        "#Find right number of components, according to a variance p\n",
        "p = 0.95\n",
        "#d = find_components(p, train_x)\n",
        "d = 215\n",
        "\n",
        "#Make PCA\n",
        "pca_train_x = transform_to(d, train_x)\n",
        "pca_val_x = transform_to(d, val_x) \n",
        "\n",
        "  \n",
        "#Calculate best k by making kNNs an checking accuracy\n",
        "best_k=1\n",
        "best_acc=0\n",
        "accs=[]\n",
        "for n in range(300, 301):\n",
        "  model = make_knn(n, pca_train_x, train_y)\n",
        "  pred_y = pred(model, pca_val_x)\n",
        "  acc = accuracy_score(val_y, pred_y)\n",
        "  accs.append(acc)\n",
        "  print(\"Acc for \",n, \" is \", acc)\n",
        "  if (acc>best_acc):\n",
        "    best_k=n\n",
        "    best_acc=acc\n",
        "\n",
        "print(\"Model gives an accuracy of: \", best_acc, \" from k = \", best_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxMsVn8bSORe"
      },
      "source": [
        "def main_val_gray_pca():\n",
        "  #Load dataset\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset loaded...\")\n",
        "\n",
        "  #Split dataset to training, validating and testing data.\n",
        "  x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "  train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "  val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "  mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "  print(\"Dataset splitted...\")\n",
        "\n",
        "  #Convert color images to gray images\n",
        "  gray_train_x = RGB_to_gray(train_x)\n",
        "  gray_val_x = RGB_to_gray(val_x) \n",
        "  print(\"Images converted...\")\n",
        "\n",
        "  #Find right number of components, according to a variance p\n",
        "  p = 0.95\n",
        "  #d = find_components(p, gray_train_x)\n",
        "  d = 159\n",
        "\n",
        "  #Make PCA\n",
        "  pca_train_x = transform_to(d, gray_train_x)\n",
        "  pca_val_x = transform_to(d, gray_val_x) \n",
        "\n",
        "  #Calculate best k by making kNNs an checking accuracy\n",
        "  model = make_knn(1, pca_train_x, train_y)\n",
        "  pred_y = pred(model, pca_val_x)\n",
        "  acc = accuracy_score(val_y, pred_y)\n",
        "  print(\"Model gives an accuracy of: \", acc)\n",
        "\n",
        "  fig = plt.figure(figsize=[20,20])\n",
        "  ax = fig.add_subplot(1,1,1)\n",
        "  conf = plot_confusion_matrix(model, pca_val_x, val_y, normalize='true', values_format='.2g')\n",
        "  conf.plot(ax = ax)\n",
        "\n",
        "main_val_gray_pca()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-tFizoSDP4s"
      },
      "source": [
        "#Load dataset\n",
        "dataset = load_data()\n",
        "print(\"Dataset loaded...\")\n",
        "\n",
        "#Split dataset to training, validating and testing data.\n",
        "x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "print(\"Dataset splitted...\")\n",
        "  \n",
        "\n",
        "#Find right number of components, according to a variance p\n",
        "p = 0.95\n",
        "#d = find_components(p, train_x)\n",
        "d = 159\n",
        "\n",
        "#Convert color images to gray images\n",
        "gray_train_x = RGB_to_gray(train_x)\n",
        "gray_val_x = RGB_to_gray(val_x)\n",
        "gray_test_x = RGB_to_gray(x_test) \n",
        "print(\"Images converted...\")\n",
        "\n",
        "#Make PCA\n",
        "pca_train_x = transform_to(d, gray_train_x)\n",
        "pca_val_x = transform_to(d, gray_val_x) \n",
        "pca_test_x = transform_to(d, gray_test_x)\n",
        "\n",
        "#starttime = time.time() \n",
        "#model = make_knn(100, pca_train_x, train_y)\n",
        "#pred_y = pred(model, pca_test_x)\n",
        "#acc = accuracy_score(y_test, pred_y)\n",
        "#print(\"Acc for test set: \", acc, \". Done in \", time.time()-starttime)\n",
        "\n",
        "#Calculate best k by making kNNs an checking accuracy\n",
        "best_k=1\n",
        "best_acc=0\n",
        "accs=[]\n",
        "for n in range (198, 231):\n",
        "  model = make_knn(n, pca_train_x, train_y)\n",
        "  pred_y = pred(model, pca_val_x)\n",
        "  acc = accuracy_score(val_y, pred_y)\n",
        "  accs.append(acc)\n",
        "  print(\"Acc for \", n, \" is \", acc)\n",
        "if (acc>best_acc):\n",
        "    best_k=n\n",
        "    best_acc=acc\n",
        "\n",
        "print(\"Accs: \", accs)\n",
        "print(\"Model gives an accuracy of: \", best_acc, \" from k = \", best_k)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQDKGzrf_Yls"
      },
      "source": [
        "#Load dataset\n",
        "dataset = load_data()\n",
        "print(\"Dataset loaded...\")\n",
        "\n",
        "#Split dataset to training, validating and testing data.\n",
        "x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "train_x, train_y = x_train[0:45000],y_train[0:45000]\n",
        "val_x, val_y = x_train[45000:],y_train[45000:]\n",
        "mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "print(\"Dataset splitted...\")\n",
        "  \n",
        "\n",
        "#Find right number of components, according to a variance p\n",
        "p = 0.95\n",
        "#d = find_components(p, train_x)\n",
        "d = 159\n",
        "d_col = 215\n",
        "\n",
        "#Convert color images to gray images\n",
        "gray_train_x = RGB_to_gray(train_x)\n",
        "gray_val_x = RGB_to_gray(val_x)\n",
        "gray_test_x = RGB_to_gray(x_test) \n",
        "print(\"Images converted...\")\n",
        "\n",
        "#Make PCA - gray\n",
        "pca_train_x = transform_to(d, gray_train_x)\n",
        "pca_val_x = transform_to(d, gray_val_x) \n",
        "pca_test_x = transform_to(d, gray_test_x)\n",
        "\n",
        "\n",
        "#Make PCA - col\n",
        "col_pca_train_x = transform_to(d_col, train_x)\n",
        "col_pca_val_x = transform_to(d_col, val_x) \n",
        "col_pca_test_x = transform_to(d_col, x_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6mZBZz2WxuK"
      },
      "source": [
        "for k in range(0,151, 10):\n",
        "  print(\"Making for col...\")\n",
        "\n",
        "  #Colour\n",
        "  starttime = time.time() \n",
        "  col_model = make_knn(k, col_pca_train_x, train_y)\n",
        "  col_pred_y = pred(col_model, col_pca_test_x)\n",
        "  col_acc = accuracy_score(y_test, col_pred_y)\n",
        "  print(\"Coloured acc for test set with k = \", k, \" is: \", col_acc, \". Done in \", time.time()-starttime)\n",
        "\n",
        "  #Gray\n",
        "  starttime = time.time() \n",
        "  model = make_knn(k, pca_train_x, train_y)\n",
        "  pred_y = pred(model, pca_test_x)\n",
        "  acc = accuracy_score(y_test, pred_y)\n",
        "  print(\"Gray acc for test set with k = \", k, \" is: \", acc, \". Done in \", time.time()-starttime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKCz-j05lwIh"
      },
      "source": [
        "  fig = plt.figure(figsize=[20, 20])\n",
        "  ax = fig.add_subplot(2,1,1)\n",
        "\n",
        "  k_col = 120\n",
        "  starttime=time.time()\n",
        "  label_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "  col_model = make_knn(k_col, col_pca_train_x, train_y)\n",
        "  conf = plot_confusion_matrix(col_model, col_pca_test_x, y_test, normalize='true',values_format  = '.2g', display_labels = label_names)\n",
        "  conf.plot(ax=ax)\n",
        "  conf.ax_.set_title(\"Test Set Performance - Colour with PCA \")\n",
        "  print(\"Time used on plot cnf: \", time.time() - starttime)\n",
        "\n",
        "  col_pred_y = pred(col_model, col_pca_test_x)\n",
        "  col_acc = accuracy_score(y_test, col_pred_y)\n",
        "  print(\"Coloured acc for test set with k = \", k_col, \" is: \", col_acc, \". Done in \", time.time()-starttime)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfCf4Z5N-hhP"
      },
      "source": [
        "def main():\n",
        "  #Load dataset\n",
        "  dataset = load_data()\n",
        "  print(\"Dataset loaded...\")\n",
        "\n",
        "  #Split dataset to training, validating and testing data.\n",
        "  x_train, y_train, x_test, y_test = dataset['train_data'],dataset['train_labels'],dataset['test_data'],dataset['test_labels']\n",
        "  train_x, train_y = x_train[0:49000],y_train[0:49000]\n",
        "  val_x, val_y = x_train[49000:],y_train[49000:]\n",
        "  mini_val_x, mini_val_y = val_x[900:], val_y[900:]\n",
        "  print(\"Dataset splitted...\")\n",
        "\n",
        "  #Convert color images to gray images\n",
        "  gray_train_x = RGB_to_gray(train_x)\n",
        "  gray_val_x = RGB_to_gray(val_x) \n",
        "  print(\"Images converted...\")\n",
        "\n",
        "  #Find right number of components, according to a variance p\n",
        "  p = 0.95\n",
        "  d = find_components(p, gray_train_x)\n",
        "\n",
        "  #Make PCA\n",
        "  pca_train_x = transform_to(d, gray_train_x)\n",
        "  pca_val_x = transform_to(d, gray_val_x) \n",
        "\n",
        "  #Calculate best k by making kNNs an checking accuracy\n",
        "  best_k, best_acc = calculate_best_k(d, gray_train_x, train_y, gray_val_x, val_y)\n",
        "  \n",
        "  print(\"Best k is \", best_k, \" with an accuracy of \", best_acc)\n",
        "  \n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}